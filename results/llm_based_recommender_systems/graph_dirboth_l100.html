<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.1.min.js" integrity="sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=" crossorigin="anonymous"></script>                <div id="94dad3cf-310c-4fdc-bb2d-cf1ce2824b8c" class="plotly-graph-div" style="height:800px; width:1200px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("94dad3cf-310c-4fdc-bb2d-cf1ce2824b8c")) {                    Plotly.newPlot(                        "94dad3cf-310c-4fdc-bb2d-cf1ce2824b8c",                        [{"customdata":["\u003cb\u003eA Prompting-Based Representation Learning Metho...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0","\u003cb\u003eRevealing Potential Biases in LLM-Based Recomme...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eReasoningRec: Bridging Personalized Recommendat...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0","\u003cb\u003eBehavior Alignment: A New Perspective of Evalua...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0","\u003cb\u003eFairEval: Evaluating Fairness in LLM-Based Reco...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eEffectiveness of LLMs in Temporal User Profilin...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eExploring the Potential of LLMs for Serendipity...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eOutfit Generation and Recommendation -- An Expe...\u003c\u002fb\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 0","\u003cb\u003eM2TRec: Metadata-aware Multi-task Transformer f...\u003c\u002fb\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 0","\u003cb\u003eConsistent Explainers or Unreliable Narrators? ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eTowards Next-Generation Recommender Systems: A ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 1","\u003cb\u003eLeveraging LLM Reasoning Enhances Personalized ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0","\u003cb\u003eMemory Assisted LLM for Personalized Recommenda...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eHeterogeneous Knowledge Fusion: A Novel Approac...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 1","\u003cb\u003eMOPI-HFRS: A Multi-objective Personalized Healt...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 4","\u003cb\u003eA Language-Driven Framework for Improving Perso...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eResearch on Conversational Recommender System C...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eMR.Rec: Synergizing Memory and Reasoning for Pe...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eAgentRecBench: Benchmarking LLM Agent-based Per...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eSynerGen: Contextualized Generative Recommender...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eLKPNR: LLM and KG for Personalized News Recomme...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 7","\u003cb\u003eMusic Recommendation with Large Language Models...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eRLHF Fine-Tuning of LLMs for Alignment with Imp...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eUser Feedback Alignment for LLM-powered Explora...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eWhat Matters in LLM-Based Feature Extractor for...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eLusifer: LLM-based User SImulated Feedback Envi...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 1","\u003cb\u003eAgentic Feedback Loop Modeling Improves Recomme...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0","\u003cb\u003eHeterogeneous User Modeling for LLM-based Recom...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eLLM-based User Profile Management for Recommend...\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0","\u003cb\u003eA Survey on LLM-based News Recommender Systems\u003c\u002fb\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 1","\u003cb\u003eIs ChatGPT Fair for Recommendation? Evaluating ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 221","\u003cb\u003eRecommender Systems in the Era of Large Languag...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 439","\u003cb\u003eLarge Language Models meet Collaborative Filter...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 94","\u003cb\u003eLLMRec: Large Language Models with Graph Augmen...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 330","\u003cb\u003eTALLRec: An Effective and Efficient Tuning Fram...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 580","\u003cb\u003eLarge Language Models are Zero-Shot Rankers for...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 461","\u003cb\u003eA survey on large language models for recommend...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 651","\u003cb\u003eChat-REC: Towards Interactive and Explainable L...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 400","\u003cb\u003eCoLLM: Integrating Collaborative Embeddings Int...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 143","\u003cb\u003eIs ChatGPT a Good Recommender? A Preliminary Study\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 348","\u003cb\u003eLLM-Rec: Personalized Recommendation via Prompt...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 124","\u003cb\u003eUncovering ChatGPT\u2019s Capabilities in Recommende...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 322","\u003cb\u003eRepresentation Learning with Large Language Mod...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 309","\u003cb\u003eRecommendation as Instruction Following: A Larg...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 301","\u003cb\u003eHLLM: Enhancing Sequential Recommendations via ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 70","\u003cb\u003eLLM-ESR: Large Language Models Enhancement for ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 67","\u003cb\u003eBERT4Rec: Sequential Recommendation with Bidire...\u003c\u002fb\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 2758","\u003cb\u003eLarge Language Models as Zero-Shot Conversation...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 218","\u003cb\u003eNoteLLM: A Retrievable Large Language Model for...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 53","\u003cb\u003eLLMRG: Improving Recommendations through Large ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 44","\u003cb\u003eBias and Unfairness in Information Retrieval Sy...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 171","\u003cb\u003eBridging Language and Items for Retrieval and R...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 297","\u003cb\u003ePALR: Personalization Aware LLMs for Recommenda...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 151","\u003cb\u003eRecMind: Large Language Model Powered Agent For...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 151","\u003cb\u003eRWKV: Reinventing RNNs for the Transformer Era\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 859","\u003cb\u003eHarnessing Large Language Models for Text-Rich ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 94","\u003cb\u003eReLLa: Retrieval-enhanced Large Language Models...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 136","\u003cb\u003eLLMRec: Benchmarking Large Language Models on R...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 49","\u003cb\u003eA Bi-Step Grounding Paradigm for Large Language...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 133","\u003cb\u003eTowards Open-World Recommendation with Knowledg...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 132","\u003cb\u003ePrompt Engineering for Large Language Models\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 341","\u003cb\u003eEnhancing Sequential Recommendation via LLM-bas...\u003c\u002fb\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 73","\u003cb\u003eONCE: Boosting Content-based Recommendation wit...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 107","\u003cb\u003ePre-train, Prompt, and Recommendation: A Compre...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 106","\u003cb\u003eMemoryBank: Enhancing Large Language Models wit...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 278","\u003cb\u003eWhere to Go Next for Recommender Systems? ID- v...\u003c\u002fb\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 274","\u003cb\u003eRecommendation as Language Processing (RLP): A ...\u003c\u002fb\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 683"],"hovertemplate":"%{customdata}\u003cextra\u003e\u003c\u002fextra\u003e","marker":{"color":"#1f77b4","line":{"color":"white","width":2},"size":[10,10,10,10,10,10,10,10,10,10,10.1,10,10,10.1,10.4,10,10,10,10,10,10.7,10,10,10,10,10.1,10,10,10,10.1,30,30,19.4,30,30,30,30,30,24.3,30,22.4,30,30,30,17.0,16.7,30,30,15.3,14.4,27.1,30,25.1,25.1,30,19.4,23.6,14.9,23.3,23.2,30,17.3,20.7,20.6,30,30,30]},"mode":"markers+text","name":"Papers","text":["A Prompting-Based Representati","Revealing Potential Biases in ","ReasoningRec: Bridging Persona","Behavior Alignment: A New Pers","FairEval: Evaluating Fairness ","Effectiveness of LLMs in Tempo","Exploring the Potential of LLM","Outfit Generation and Recommen","M2TRec: Metadata-aware Multi-t","Consistent Explainers or Unrel","Towards Next-Generation Recomm","Leveraging LLM Reasoning Enhan","Memory Assisted LLM for Person","Heterogeneous Knowledge Fusion","MOPI-HFRS: A Multi-objective P","A Language-Driven Framework fo","Research on Conversational Rec","MR.Rec: Synergizing Memory and","AgentRecBench: Benchmarking LL","SynerGen: Contextualized Gener","LKPNR: LLM and KG for Personal","Music Recommendation with Larg","RLHF Fine-Tuning of LLMs for A","User Feedback Alignment for LL","What Matters in LLM-Based Feat","Lusifer: LLM-based User SImula","Agentic Feedback Loop Modeling","Heterogeneous User Modeling fo","LLM-based User Profile Managem","A Survey on LLM-based News Rec","Is ChatGPT Fair for Recommenda","Recommender Systems in the Era","Large Language Models meet Col","LLMRec: Large Language Models ","TALLRec: An Effective and Effi","Large Language Models are Zero","A survey on large language mod","Chat-REC: Towards Interactive ","CoLLM: Integrating Collaborati","Is ChatGPT a Good Recommender?","LLM-Rec: Personalized Recommen","Uncovering ChatGPT\u2019s Capabilit","Representation Learning with L","Recommendation as Instruction ","HLLM: Enhancing Sequential Rec","LLM-ESR: Large Language Models","BERT4Rec: Sequential Recommend","Large Language Models as Zero-","NoteLLM: A Retrievable Large L","LLMRG: Improving Recommendatio","Bias and Unfairness in Informa","Bridging Language and Items fo","PALR: Personalization Aware LL","RecMind: Large Language Model ","RWKV: Reinventing RNNs for the","Harnessing Large Language Mode","ReLLa: Retrieval-enhanced Larg","LLMRec: Benchmarking Large Lan","A Bi-Step Grounding Paradigm f","Towards Open-World Recommendat","Prompt Engineering for Large L","Enhancing Sequential Recommend","ONCE: Boosting Content-based R","Pre-train, Prompt, and Recomme","MemoryBank: Enhancing Large La","Where to Go Next for Recommend","Recommendation as Language Pro"],"textfont":{"size":8},"textposition":"middle center","x":[1.0,0.9956059820218981,0.9824625428755761,0.9606851875768402,0.9304652963070866,0.8920684425573865,0.8458320592590974,0.7921624734111293,0.731531335263669,0.6644714734388217,0.5915722124135223,0.5134741935148419,0.43086374494097046,0.344466850284333,0.2550427685616765,0.16337736181853024,0.070276188945293,-0.023442573603260443,-0.11695532197208247,-0.20944026276614447,-0.30008463500034077,-0.3880918526722496,-0.47268850518856537,-0.5531311541251994,-0.6287128665908847,-0.6987694277788417,-0.7626851781103818,-0.8198984236734246,-0.8699063724087902,-0.9122695526648968,-0.9466156752904341,-0.9726429053248131,-0.9901225145346509,-0.9989008914857114,-0.9989008914857115,-0.9901225145346509,-0.972642905324813,-0.9466156752904342,-0.9122695526648967,-0.8699063724087903,-0.8198984236734245,-0.762685178110382,-0.6987694277788418,-0.6287128665908849,-0.5531311541251992,-0.4726885051885656,-0.3880918526722498,-0.3000846350003406,-0.2094402627661449,-0.11695532197208272,-0.023442573603260467,0.0702761889452932,0.16337736181852977,0.25504276856167624,0.34446685028433294,0.4308637449409707,0.5134741935148417,0.5915722124135223,0.6644714734388218,0.7315313352636688,0.7921624734111292,0.8458320592590974,0.8920684425573866,0.9304652963070865,0.9606851875768402,0.9824625428755762,0.9956059820218981],"y":[0.0,0.09364148953435077,0.18646005429168117,0.27764000138750056,0.36638003816824616,0.45190031399993386,0.5334492736235703,0.6103102618497921,0.6818078215504377,0.7473136296000771,0.8062520186022298,0.8581050358751443,0.9024169952385883,0.9387984816003864,0.9669297731502506,0.9865636510865465,0.9975275721840101,0.9997251851098159,0.9931371771625542,0.9778214439929451,0.953912580814779,0.9216206995773375,0.8812295824940284,0.8330941881540915,0.7776375321337522,0.7153469695201276,0.6467699120171988,0.5725090172720719,0.49321689269790747,0.4095903603365063,0.3223643331611538,0.23230535663498308,0.14020487228188577,0.04687226246994031,-0.046872262469940064,-0.14020487228188555,-0.23230535663498328,-0.3223643331611536,-0.4095903603365065,-0.49321689269790725,-0.572509017272072,-0.6467699120171987,-0.7153469695201273,-0.777637532133752,-0.8330941881540916,-0.8812295824940283,-0.9216206995773374,-0.953912580814779,-0.977821443992945,-0.9931371771625541,-0.9997251851098159,-0.9975275721840101,-0.9865636510865465,-0.9669297731502506,-0.9387984816003864,-0.9024169952385882,-0.8581050358751444,-0.8062520186022298,-0.747313629600077,-0.6818078215504381,-0.6103102618497923,-0.5334492736235703,-0.4519003139999336,-0.3663800381682465,-0.27764000138750067,-0.18646005429168103,-0.09364148953435125],"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":20},"text":"Recommendation as Language Processing (RLP): A ...","x":0.5,"xanchor":"center"},"margin":{"b":20,"l":5,"r":5,"t":40},"xaxis":{"showgrid":false,"zeroline":false,"showticklabels":false},"yaxis":{"showgrid":false,"zeroline":false,"showticklabels":false},"showlegend":true,"hovermode":"closest","width":1200,"height":800},                        {"responsive": true}                    )                };            </script>        </div>
</body>
</html>